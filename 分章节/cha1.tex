%-------------------第一章-------------------
\chapter{The Whitehead lemma and $K_1(A)$}
\label{cha:1the_whitehead_lemma_and_k_1}
\setcounter{page}{1}
The beginning is predictable enough $\cdots$ We consider a ring $A$. This assumes associativity. In general we shall also suppose thar $A$ has a multipicative identity $1$; at the end of this chapter is a discussion of how the theory can be made to accommondate the case when it doesn't. In order to look at the {\em general linear group} $GL(A)$ we first study, for $n\geqslant 1$, $GL_n(A)$, which is defined as the group of units $(M_n(A))^*$ of the ring $M_n(A)$\index{matrix ring, $M_nA$} of $n\times n$-matrices with entries in $A$ (under the usual matrix addition and multiplication). The inclusion $M_n(A)\hookrightarrow M_{n+k}(A)$ is given by matrix direct sum with the $k\times k$-identity matrix $I_k$; thus $\alpha \to \alpha \oplus I_k=\begin{pmatrix}      
    \alpha & 0 \\
    0 & I_k
\end{pmatrix}$. 

Notable elements of $GL_n(A) (n\geqslant 2)$\index{general linear group,!$GL_n(A)$} are the {\em elementary matrices}, those with (at most) one non-zero off-diagonal entry and $1$s right down the diagonal. Thus the elementary matrix $e_{ij}^a$ has $i\neq j, a\in A$ and $e_{ij}^a-I_n$ is the zero matrix apart from $a$ in the $(i,j)$-slot. $E_n(A)$ \index{elementary matrices@elementary matrices,!$E_n A$} is the subgroup of $GL_n(A)$ they generate:
\[E_n(A)=\langle e_{ij}^a | a\in A, i\neq j\in \{1,2,\cdots,n\}\rangle.\]

The key rules for manipulating these objects are encapsulated in the relations of the {\em $n$-th Steinberg group} $St_n(A)$\index{Steinberg group,! $St_n(A)$} which is designed to be an extension of $E_n(A)$. Thus it has generators $x_{ij}^a$, one corresponding to each $e_{ij}^a$, subject to the ralations
\[x_{ij}^a x_{ij}^b=x_{ij}^{a+b},\]
and, if $i\neq l$ (so that $n\geqslant 3$)
\begin{equation*}
	[x_{ij}^a,x_{kj}^b]=\left\{
	\begin{array}{cc}
	1 & j\neq k,\\
	x_{il}^{ab} & j=k.
	\end{array}
	\right.
\end{equation*}
Incidentally, although it doesn't affect this formula whichever way around we define our commutators, for the record we shall be using the notation
\[[x,y]=xyx^{-1}y^{-1}.\]
Since the relations between $x_{ij}$'s are also valid among $e_{ij}$'s, the function $x_{ij}^a \mapsto e_{ij}^a$ defines a homomorphism $\varphi\colon  St_n(A)\rightarrow GL_n(A)$ whose image is $E_n(A)$. I haven't bothered to burden $\varphi$ with the subscript $n$ because of the compatibility of $\varphi$ with $GL_n(A)\hookrightarrow GL_{n+p}(A)$ and the natural homomorphism $\iota\colon St_n(A)\rightarrow St_{n+p}(A)$ obtained by extending the domain of subscripts. In other words, if we pass to the limit of each directed set of groups and write \index{general linear group,!$GL(A)$}$GL(A)=\cup GL_n(A), E(A)=\cup E_n(A), St(A)=\varinjlim St_n(A)$\index{Steinberg group,! $St(A)$}, then $\varphi$ is a homomorphism from $St(A)$ to $GL(A)$ with image $E(A)$\index{elementary matrices@elementary matrices,!$EA$}. Now $\varphi$ carries a huge weight on its shoulders, for it determines, as we shall soon see, both $K_1(A)$ and $K_2(A)$. Close scrutiny is therefore called for. As ever, $Z(G)$ denotes the centre of a group $G$.
\begin{lemma}\label{1.1}
The homomorphism $\varphi\colon  St_n(A)\rightarrow GL_n(A)$ has as cokernel (the set) $GL_n(A)/E_n(A)$ and as kernel $Y_n=St_n(A)\cap \iota^{-1}Z(St_m(A)), 2\leqslant n < m.$
\end{lemma}
\begin{proof}
A matrix $(a_{ij})$ commutes with $e_{kl}^1$ if and only if $a_{kl}=0$ and $a_{kk}=a_{ll}$. Because the embedding $E_nA\hookrightarrow E_mA$ adjoins $1$'s down the extension of the diagonal, it follows that
\[E_nA\cap Z(E_mA)=1,\]
whence
$St_nA\cap \iota^{-1}Z(St_m(A))\leqslant Y_n.$
To complete the proof it suffices (bearing in mind that $Y_n=St_nA\cap \iota^{-1}Y_m$) to apply the next lemma to show that $Y_m\leqslant Z(St_mA)$.
\end{proof}
\begin{lemma}\label{1.2}
Suppose a group $G$ is the group union of subgroups $G_1,G_2$, each normal in the subgroup generated by the complement of the other. If a normal subgroup $Y$ of $G$ has
$Y\cap G_i=1$ $(i=1,2)$, then $Y$ is central in $G$.

\end{lemma}
\begin{proof}
For $i=1,2$, $Y$ and $G_i$ are normal in $gp(G-G_{3-i})$. So $[Y,G_i]\leqslant Y\cap G_i=1$; that is, elements of $Y$ commute with all elements of $G_1,G_2$. Hence they commute with all products of such elements, which is to say, with all elements of $G$.

We shall choose for our $G_1,G_2$ the ``first row" and ``first column" subgroups of $St_nA$, defined respectively as the subgroups
\[FR_n=gp\{x^a_{1j}|a\in A, 1<j\leqslant n\},FC_n=gp\{x_{i1}^a|a\in A,1<i\leqslant n\}.\]
Now any two elements $x_{1j}^a,x_{1k}^b$ commute, so that $FR_n$ is abelian, enabling a typical element to be shuffled into the standard form $x_{12}^{a_2}x_{13}^{a_3}\cdots x_{1n}^{a_n}$, which $\varphi$ maps to
\[e_{12}^{a_2}e_{13}^{a_3}\cdots e_{1n}^{a_n}=\left(\begin{array}{c|c}
1& a_2\cdots a_n \\
\hline
0&I_{n-1}\\
\end{array}\right) \]
Such a matrix can only be the identity matrix if $a_2=\cdots=a_n=0$. Thus $FR_n\cap Y_n=1$. 
Meanwhile
\[FR_n\trianglelefteq gp(St_nA-FC_n)=gp\{x_{ij}^a|a\in A,1\leqslant i\leqslant n,1<j\leqslant n\}\]
because
\begin{equation*}
\begin{array}{rl}
&x_{ij}^{-a}x_{1k}^{a_k}x_{ij}^a\\
=& x_{1k}^{a_k}[x_{1k}^{-a_k},x_{ij}^{-a}]\\
=&\begin{cases}
x_{1k}^{a_k} &k\neq i,\\
x_{1k}^{a_k}x_{1j}^{a_ka} &k=i.
\end{cases}
\end{array}
\end{equation*}
The corresponding conditions on $FC_n$ may be proved similarly, or else deduced from the above via the involutions $x_{ij}^a\mapsto x_{ji}^a$ and $(a_{ij})\mapsto (a_{ji})$ of $St_nA$ and $GL_nA$ respectively, since $\varphi$ commutes with these involutions. Finally, we have that $St_nA=gp(FR_n,FC_n)$; in fact, because $x_{ij}^a=[x_{il}^a,x_{lj}^1]$, 
$gp(St_nA-FC_n)=gp(FR_n,[FC_n,FR_n])=FR_n[FC_n,FR_n]$ by the normality already demonstrated. Together with the corresponding result on $FC_n$, this decomposes $St_nA$ as
\[St_nA=FR_n[FC_n,FR_n]FC_n.\]
In summary, the various conditions of (\ref{1.2}) are satisfied, so that the proof of (\ref{1.1}) goes through.
\end{proof}
For both $St_nA$ and $E_nA$ $(n\geqslant 3)$, each generator is expressible as a commutator\index{commutator} of other generators,and thus each element as a product of commutators. Recalling that a group equal to its commutator subgroup is termed {\em perfect}\index{perfect group}, we therefore record
\begin{prop}
	For $n \geqslant 3$, $St_n A$ and $E_n A$ are perfect groups.
\end{prop}
This prompts a digression.
\section*{PERFECT GROUPS}
Equivalent notational ways of expressing the fact that a group $P$ is perfect are
\[P=[P,P]=P^{(1)},\]
or
\[P/[P,P]=P_{ab}=H^1(P,\Z)=0.\]
Since perfect groups are to have a pivotal (``centrar") role in the development of the theory, we itemise some of their more obvious properties. First note that homomorphisms send commutators to commutators.
\begin{prop}
a) The homomorphic image of a perfect group is also perfect.
\end{prop}
Indeed, $\varphi St_nA=E_nA$ provides a ready example. An application of (a)is to the collection of subgroups of a given group, $G$ say. The collection of perfect subgroups is therefore closed under automorphisms of $G$.Further, it is evidently closed under the operation of group union. Hence
\setcounter{theorem}{\value{theorem}-1} %修改计数器
\begin{prop}
b) Any group $G$ has a maximal perfect subgroup, the perfect radical $PG$\index{perfect radical, $PG$}, which is a characteristic subgroup of $G$.
\end{prop}
Immediate consequences are
\setcounter{theorem}{\value{theorem}-1} %修改计数器
\begin{prop}\label{1.4}
c) If $\phi\colon  G \rightarrow H$ is a homomorphism, then $\phi PG \leqslant PH$.
\end{prop}
\setcounter{theorem}{\value{theorem}-1} %修改计数器
\begin{prop}
d) If $\phi\colon  G \rightarrow H$ is a homomorphism and $ PH= 1$, then  $PG \leqslant \ker \phi$.
\end{prop}
The falsity of the converse to (d) is exposed by the (extreme) example
\[C=\langle x_{12}^1\rangle *\langle x_{13}^1\rangle *\langle x_{21}^1\rangle *\langle x_{31}^1\rangle \twoheadrightarrow H=St_3\Z.\]
Because $G$ (and so any subgroup of $G$) is free, $PG=1$, while $PH=H$. The example further shows that the property of having trivial perfect radical is not preserved by epimorphisms and therefore differs, in general, from the property of solubility, to which it is equivalent in the finite case. This situation may be described by
\begin{prop}\label{1.5}
$G$ is soluble\index{soluble group} if and only if $PG=1$ and for some $i$, $G^{(i)}$ is finite.
\end{prop}
\begin{proof}
The appropriate definition of solubility is that $G^{(n)}(=[G^{(n-1)},G^{(n-1)}])$ be trivial for some $n$. This immediately forces $PG=(PG)^{(n)}\leqslant G^{(n)}$ to be trivial too. Conversely,the finiteness of some $G^{(i)}$ (or equivalently, the finiteness of some $G^{(j)}/Z(G^{(j)}$, since a lemma of Schur asserts that $G^{(j+1)}$ finite follows) forces the derived series of $G^{(i)}$ to terminate after a finite number of steps, $n$ say. But then $G^{(i+n+1)}=G^{(i+n)}$ says that $G^{(i+n)}$ is perfect, whence
$G^{(i+n)}\leqslant PG=1$.
\end{proof}

A key question suggested by (\ref{1.4}) c) (due to resurface later on in (\ref{5.11}),(\ref{6.8})) asks when an epimorphism preserves perfect radicals. Here is a partial answer. (Recall that the $n$-th centre $\zeta_n G$\index{centre,!n-th@$n$-th--of a group, $\zeta_n G$} of $G$ is defined by $\zeta_0 G=1,\zeta_1G=Z(G),\zeta_{i+1}G=\{g\in G|[G,\langle g\rangle]\leqslant \zeta_iG\}$, making
$\zeta_0 G\leqslant \zeta_1 G\leqslant \cdots$ the upper central series\index{upper central $\pi$-series} of $G$.)
\begin{prop}
\label{1.6}
The group extension $\phi\colon  G\twoheadrightarrow H$ with kernel $K\leqslant G$ has $PH = \phi PG$ provided either\\
(a) $\phi$ is split,\\
(b) $K\leqslant PG.\zeta_n G$ for some $n$,or\\
(c) $G^{(j)}\leqslant K.PG$ for some $j$.
\end{prop}
\begin{proof}
In each case it remains, after (\ref{1.4}) c), only to prove that $PH \leqslant \phi PG$. For (a), if the monomorphism $\psi\colon  H\rightarrowtail G$ splits $\phi$, then (\ref{1.4}) c) again yields that $\psi PH \leqslant  PG$, whereupon $PH=\phi \psi PH\leqslant PG$.

(b) Define $L=\phi^{-1}(PH)$. Since for all $i$, $PH=(PH)^{(i)}$, we have that $L=L^{(i)}K$. To use first the case $i=1$, $L\leqslant L^{(1)}.PG.\zeta_n G$ implies
\[L^{(n)}\leqslant (L^{(1)}.PG.\zeta_n G)^{(n)}=(L^{(1)}.PG)^{(n)}=L^{(n+1)}.PG,\]
and so therefore (because $PG=(PG)^{(1)}$)
\[L^{(n)}.PG\leqslant L^{(n+1)}.PG=(L^{(n)}.PG)^{(1)}.\]
In other words $L^{(n)}.PG$ is a perfect subgroup of $G$, whereupon $L^{(n)}.PG\leqslant PG$. Thus $L^{(n)}\leqslant PG$. Then the formula $L=L^{(n)}.K$ reveals that $L\leqslant PG.K$, leaving
\[PH=\phi L\leqslant \phi(PG.K)=\phi PG.\]

(c) One can argue either directly, viz.
\[PH=(PH)^{(j)}\leqslant H^{(j)} \leqslant  \phi G^{(j)} \leqslant \phi(K.PG)=\phi PG,\]
or use (\ref{1.5}), noting that if $G/K.PG$ is soluble, then so is its image $H/\phi PG$. 
\end{proof}

In particular, (\ref{1.6}) b) handles all central extensions, as well as those with perfect kernel. An important example of the latter type is worth commemorating, along with its converse (which applies (\ref{1.4}) d)).
\begin{prop}
For a perfect normal subgroup $P$ of $G$, $P(G/P)=1$ if and only if $P=PG$.
\end{prop}
End of digression.

We return now to $E_n A$, and look at its relationship to $GL_nA$. Note that if our ring is already a ring of matrices $M_kA$, then we may equate $M_n(M_k A)$ with $M_{nk}A$, so long as we make no claims concerning compatibility with inclusions $M_nA\hookrightarrow M_{n+1}A$, etc.\ 
\refstepcounter{theorem}
\begin{equation}
  E_2(M_nA)\leqslant E_{2n}A.
\end{equation}

\begin{proof}
$E_2(M_nA)$ is generated by $e_{12}^\alpha$ and its transpose $e_{21}^\alpha$, where $\alpha$ ranges over all matrices
$\alpha=(a_{ij})$ of $M_nA$. If we write
\[\alpha=\left(
\begin{array}{c|c}
 & a_{1n}\\
\alpha' &\vdots\\
& a_{nn}\\
\end{array}\right), \]
then
\[e_{1,2}^{\alpha}=\left(
\begin{array}{c|c|c}
 & & a_{1n}\\
I_n& \alpha' &\vdots\\
& & a_{nn}\\
\hline
0& \multicolumn{2}{c}{I_n}
\end{array}\right)=e_{1,2n}^{a_{1n}}\cdots e_{n,2n}^{a_{nn}}\left(
\begin{array}{c|c|c}
I_n & \alpha'& \multirow{2}*{0}\\
\cline{1-2}
0&I_{n-1} & \\
\hline
\multicolumn{2}{c|}{0}& 1\\
\end{array}\right) \]
which allows us to iterate, to conclude with
\[e_{12}^{\alpha}=(\prod_{i=1}^n e_{i,2n}^{a_{in}})\cdots(\prod_{i=1}^n e_{i,n+j}^{a_{ij}})\cdots(\prod_{i=1}^n e_{i,n+1}^{a_{i1}}).\]
\end{proof}

The inclusion $GL_nA\hookrightarrow GL_{n+k}A$, $\alpha\mapsto \alpha\oplus I_k$, is implicit in the statements of the next lemmas.
\begin{lemma}
If $\alpha \in GL_nA$, then\\
(a) $\alpha$ is conjugate in $GL_{2n}A$ to $I_n\oplus \alpha=\begin{pmatrix} I_n & 0 \\ 0 &  \alpha \end{pmatrix}$ by an element of $E_{2n}$, and\\
(b) $\alpha\oplus \alpha^{-1}=\begin{pmatrix} \alpha & 0 \\ 0 &  \alpha^{-1} \end{pmatrix}\in E_{2n}A$
\end{lemma}
\begin{proof}
First observe that, for any unit $a\in A^*$,
\[\begin{pmatrix} 0 & a \\ -a^{-1} &  0 \end{pmatrix}=e_{12}^ae_{21}^{-a^{-1}}e_{12}^{a}\in E_{2n} A.\]
Now $a\in (M_nA)^*$. Accordingly $\begin{pmatrix} 0 & \alpha \\ -\alpha^{-1} &  0 \end{pmatrix}\in E_{2n}A$ by(1.8). It remains to observe that
\[\begin{pmatrix} \alpha &  0\\ 0 &  I_n\end{pmatrix}=\begin{pmatrix} 0 & I_n \\ -I_n &  0 \end{pmatrix}\begin{pmatrix}  I_n&  0\\ 0 & \alpha \end{pmatrix}\begin{pmatrix} 0 & -I_n \\ I_n &  0 \end{pmatrix}.\]
while
\[\begin{pmatrix} \alpha & 0 \\ 0 &  \alpha^{-1} \end{pmatrix}=\begin{pmatrix} 0 & \alpha \\ -\alpha^{-1} &  0 \end{pmatrix}\begin{pmatrix} 0 & -I_n \\ I_n &  0 \end{pmatrix}.\]
\end{proof}
It is more useful to have a generalized version of (1.9)a).
\begin{prop}
If $\beta_n\in GL_nA$, then $\beta_n$ is conjugate in $GL_{2(m+n)}A$ to $I_m\oplus \beta_n$ by an element of
$E_{2(m+n)}A$.
\end{prop}

\begin{proof}
An immediate application of (1.9)a) gives $(\beta_n\oplus I_m)\oplus (I_m\oplus I_n)$ conjugate to
$I_m\oplus I_n \oplus \beta_n\oplus I_m $. Now if $\alpha =\prod_\lambda e_{i_\lambda,j_\lambda}^{a_\lambda}\in E_{2n}A$, then $\prod_\lambda e_{m+i_\lambda,m+j_\lambda}^{a_\lambda}=I_m\oplus \alpha \in E_{m+2n}A$. Combination with a second application of (1.9)a) produces conjugation to $I_m\oplus\beta_n \oplus I_n$ as required.
\end{proof}

Now suppose $\alpha_1,\alpha_2\in GL_nA$. Then
\[[\alpha_1\oplus I_n,\alpha_2\oplus I_n]=[\alpha_1,\alpha_2]\oplus I_n=(\alpha_1\oplus \alpha_1^{-1})(\alpha_2\oplus \alpha_2^{-1})(\alpha_1^{-1}\alpha_2^{-1}\oplus \alpha_2\alpha_1 ),\]
an element of $E_{2n}A$ by(1.9). Thus$[GL_nA,GL_nA]\leqslant E_{2n}A$ and we have
\[[E_nA,E_nA]\leqslant [GL_nA,GL_nA]\leqslant E_{2n}A=[E_{2n}A,E_{2n}A],\]
using (1.3). Passage to the limit gives the instrumental
\begin{lemma}[Whitehead Lemma]\index{Whitehead lemma}
$[EA,EA]=[GLA,GLAJ=EA=P(GLA)$.
\end{lemma}

In particular we have $EA$ normal, indeed characteristic, in $GLA$; moreover $GLA/EA=\coker \varphi$ is an abelian group and is often known as the {\em Whitehead group}\index{Whitehead group} of $A$ (just as, to be honest, are some of its quotient groups). If the name is a little uncertain, there is no doubt whatever about the symbol: let
\[K_1A=GLA/P(GLA)=GLA/EA=GLA_{ab}=H_1(GLA;\Z).\]
Since the constructions $GL$, $E$ and $St$ are functorial (in fact $E$ and $St$ even convert ring epimorphisms to group epimorphisms), we have $K_1$as a covariant functor from the category of rings (still, for the moment, with a $1$) and ring homomorphisms to the category of abelian groups and group homomorphisms. This ought to constitute a simplification, for which one should in principle be grateful. We'll therefore look at some of the easier examples. However, first a comment on the group operation in $K_1$. The multiplication inherited by any quotient of $GLA$ is of course matrix multiplication; in this instance (1.10) offers an alternative description.For it reveals that, given $\alpha_m \in GL_m A$, $\beta_n\in GL_n A$, the multiplication in $K_1A$
\[(\alpha_m,\beta_n)\mapsto (\alpha_m\oplus I_n)\cdot(\beta_n\oplus I_m)\]
coincides with
\[(\alpha_m,\beta_n)\mapsto (\alpha_m\oplus I_n)\cdot(I_m\oplus \beta_n )\alpha_m\oplus\beta_n.\]

We now move in two opposite directions (one at a time). First, we specialise to commutative rings, where, by considering Euclidean rings and fields we can do the computations easily enough. Then we generalise to rings without a multiplicative identity.

\section*{COMMUTATIVE RINGS}\index{commutative ring}
The easiest examples for the purposes of calculation occur when $A$ is commutative. For the determinant homomorphism \index{determinant homomorphism@determinant homomorphism, $\det$}$GL_nA\longrightarrow A^*$ is invariant under the inclusion $GL_nA\hookrightarrow GL_{n+1}A$. It may therefore be regarded as being defined on $GLA$, where its kernel, the {\em special linear group} $SLA$\index{special linear group, $SLA$}, certainly includes every elementary matrix and thus $EA$. So it induces on the quotient group $K_1A$ a homomorphism $\det\colon  K_1A\longrightarrow A^*$. Now $\det$ has a right inverse given by $A^*=GL_1A\hookrightarrow GLA\longrightarrow K_1A$. If we define $SK_1A=SLA/EA$ as the kernel of $\det$ we then have
\begin{prop}
For $A$ commutative, the determinant homomorphism induces
\[K_1A=SK_1A\oplus A^*.\]
\end{prop}

We can carry out the calculation in Euclidean rings\index{Euclidean ring} without further ado. The key property we require of the Euclidean algorithm\index{Euclidean algorithm}, a function $\delta\colon  A-\{0\}\longrightarrow \N$, is that for any two non-zero elements $a,b$ there is a third, $q$ say, with either $a=qb$ or else $\delta(a—qb)<\delta(b)$. Both $\Z$ and polynomial rings over fields obviously satisfy this condition, as do discrete valuation rings\index{discrete valuation ring} (e.g.\  $\Z_{(p)}$ and power series rings over fields) and indeed, somewhat vacuously, fields themselves.

Consider a typical element of $SK_1A=SLA/EA$; suppose $\alpha=(a_{ij})\in SL_nA$ is a coset representative---we attack its final column. (This of course follows best military tradition. The reader will also observe how we compensate for lack of sophisticated weaponry by sheer, dogged persistence.) At most $n-1$ of the elements $a_{in}$ can vanish ($\alpha$ is, after all, invertible), which makes the integer $\bar{\delta}(\alpha)$, given by
\[\bar{\delta}(\alpha)=(n-1-\#\{i|a_{in}=0\}).\min\{\delta(a_{in})|a_{in}\neq 0\},\]
well-defined and non-negative, attaining the value $0$ only when the final column of $\alpha$ contains a single non-zero entry. Now suppose $\delta(a_{tn})=\min \{\delta(a_{in})|a_{in}\neq 0\}$. For each $a_{in}\neq 0 (i\neq t)$ the algorithm produces $q_i\in A$ allowing $a_{in}-q_ia_{tn}$ to be either zero or have $\delta$-value less than $\delta(a_{tn})$. If $a_{in}=0$ or $i=t$, then put $q_i=0$. It follows that the matrix $\alpha'=(\prod_{i=1}^n e_{it}^{-q_i})\alpha$ has its last column composed of elements $a_{in}'=a_{in}-q_ia_{tn}$. Accordingly
\[\bar{\delta}(\alpha')< \bar{\delta}(\alpha).\]
Iteration finally yields a coset representative with just the one non-zero entry in the final column. Should this be in the $i$th row where $i\neq n$, then premultiplication by $e_{in}^{-1}e_{nj}^1$ converts it to the $(n,n)$-position. Again, this element emerges as a factor in the expansion of the determinant and so must be a unit, say $a\in A^*$. Use of (1.9) enables us to premultiply by the matrix $I_{n-2}\oplus a\oplus a^{-1}\in E_nA$, to obtain a coset representative $\bar{\alpha}$ with last column comprising $\bar{a_{in}}=\delta_{in}$.

Thus
\[\bar{\alpha}=\begin{pmatrix} \beta & 0 \\ \bar{a} &  1 \end{pmatrix}=\begin{pmatrix} I_{n-1} & 0 \\ \bar{\alpha}\beta^{-1} &  1 \end{pmatrix}\begin{pmatrix} \beta & 0 \\ 0 &  1 \end{pmatrix}.\]
Since $\begin{pmatrix} I_{n-1} & 0 \\ \bar{\alpha}\beta^{-1} &  1 \end{pmatrix}\in E_n A$ expands as $\prod_{j<n}e_{n_j}^{c_j}$ for suitable elements $C_j\in A$, we are finally left with a coset representative of form $\beta \oplus I_1 \in SL_{n-1}A$. Well, not quite finally, for we now have to repeat the whole procedure to derive a coset representative in $SL_{n-2} A$ and so on, until ultimately in $SL_1A$ where it can only be the identity matrix. The conclusion is that $SK_1A=0$, making $K_1A=A^*$.

\section*{PSEUDO-RINGS}

To finish this chapter, we fulfil our pledge to discuss the case of rings which may lack an
 identity element. Let $\Lambda$ be such a pseudo-ring\index{matrix pseudo-ring, $m\Lambda$}. Define $m\Lambda$ to be the set $\Lambda_{fs}^{\N\times \N}$ of functions
$\alpha\colon  \N\times \N\longrightarrow \Lambda$ with finite support (in other words, of finite matrices over $\Lambda$), on which we impose the obvious (matrix) operations $+$ and $\circ$, given by
\[(\alpha+\beta)(i,j)=\alpha(i,j)+\beta(i,j)\]
\[(\alpha \circ \beta)(i,j)=\sum_{k\in \N} \alpha(i,k)\beta(k,j).\]
(Because $\alpha,\beta\in \Lambda_{fs}^{\N\times \N}$, the summation is finite.) Evidently $m\Lambda$ is another pseudo-ring and $m$ is in fact a functor from the category $\mathbb{R}ng$\index{Rng@$\mathbb{R}ng$} of pseudo-rings and their homomorphisms to itself.
Tempting though it is to iterate this procedure, the following lemma stops the impulse getting out of hand.
\begin{lemma}
A bijection $\gamma\colon  \N\longrightarrow \N\times \N$ induces a natural equivalence $\gamma^*\colon  m\circ m\iso m$ of functors $\mathbb{R}ng\longrightarrow \mathbb{R}ng$.
\end{lemma}
\begin{proof}
Let $\N_1,\N_2,\N'_1,\N'_2,\N''_1,\N''_2$ represent various copies of the natural numbers. Then, in terms of sets, the bijections $\gamma\colon   \N_i \longrightarrow \N'_i\times \N''_i$ $(i=1,2)$ induce natural bijections
\begin{equation*}
\begin{array}{rcl}
m(m\Lambda)& = &(\Lambda_{fs}^{\N'_1\times \N'_2})_{fs}^{\N''_1\times \N''_2} \\
 & \cong & \Lambda_{fs}^{\N'_1\times \N'_2\times \N''_1\times \N''_2}\\
& \cong &\Lambda_{fs}^{(\N'_1\times \N''_1)\times (\N'_2\times \N''_2)} \\
&\iso &\Lambda_{fs}^{\N_1\times \N_2}=m\Lambda.
\end{array}
\end{equation*}
This means that if $\gamma(i)=(\gamma'(i),\gamma''(i))\in \N'\times \N''$, then (for $\beta\in m(m\Lambda)$)
\[\gamma^*(\beta)(i,j)=(\beta(\gamma''(i),\gamma''(j)))(\gamma'(i),\gamma'(j)).\]
It is easy enough to see that $\gamma^*$ is an additive homomorphism. Verification  that$\gamma^*$ preserves the $\circ$ operation is a little trickier. For $\beta_1,\beta_2\in m(m\Lambda)$ we can write
\begin{align*}
\gamma^*(\beta_1\circ \beta_2)(i,j)=&((\beta_1\circ \beta_2)(\gamma''(i),\gamma''(j)))(\gamma'(i),\gamma'(j))\\
=&\sum_{k\in \N}(\beta_1(\gamma''(i),k)\circ \beta_2(k,\gamma''(j)))(\gamma'(i),\gamma'(j))\\
=&\sum_{h,k\in \N}(\beta_1(\gamma''(i),k))(\gamma'(i),h)\cdot (\beta_2(k,\gamma''(j)))(h,\gamma'(j))\\
=&\sum_{(h,k)\in \N\times \N}(\beta_1(\gamma''(i),\gamma''\gamma^{-1}(h,k)))(\gamma'(i),\gamma'\gamma^{-1}(h,k))\cdot (\beta_2(\gamma''\gamma^{-1}(h,k),\gamma''(j)))(\gamma'\gamma^{-1}(h,k),\gamma'(j))\\
=&\sum_{n\in \N}(\beta_1(\gamma''(i),\gamma''(n)))(\gamma'(i),\gamma'(n))\cdot (\beta_2(\gamma''(n),\gamma''(j)))(\gamma'(n),\gamma'(j))\\
=&\sum_{n\in \N}\gamma^*(\beta_1)(i,n)\cdot \gamma^*(\beta_2)(n,j)\\
=&(\gamma^*(\beta_1)\cdot \gamma^*(\beta_2))(i,j).
\end{align*}
Hence $\gamma^*$ is a pseudo-ring homomorphism and the proof is complete.

\end{proof}

The bijection $\gamma$ is destined to have its really big moment in another ten chapters' time. For the present, though, it has served its purpose. We now call upon two further functors. The former takes $ \mathbb{R}ng$ to the category $\mathbb{M}onoid$\index{monoid,@$\mathbb{M}onoid$} of monoids and their homomorphisms. It retains the underlying set but synthesises from the two pseudo-ring operations a monoid multiplication namely 
\[\alpha \star \beta=\alpha+\beta+\alpha\circ \beta,\]
for which the previous additive identity $0$ serves as the multiplicative identity. In the case of the matrix pseudo-ring/monoid $m\Lambda$ we next apply the functor which restricts to $(m\Lambda)^*$, the group of units of $m\Lambda$ considered as a {\em monoid}. This is what we wish to regard as the appropriate generalization of $GLA$; so let us check its credentials. If $1\in A$ then there is an obvious bijection
\[GLA\longrightarrow (mA)^*,\alpha\mapsto \alpha-I.\]\index{monoid,!$mA$ as --}
Because $\alpha\beta-I=(\alpha-I)+(\beta-I)+(\alpha-I)\circ(\beta-I)$, this defines an isomorphism, making $(m\Lambda)^*$ a bona fide generalization after all.

Collating all this information gives a valuable corollary to (1.13).
\begin{prop}
The functors $GL$ and $GL\circ m\colon  {\rm Ring}\longrightarrow{\rm Group}$ are naturally equivalent.
\end{prop}
Perhaps the most important way in which pseudo-rings tend to arise is as ideals of rings. The reader has between now and Chapter 3 to decide on the most suitable ring of which $mA$ ($A$ a ring) is an ideal.
% chapter the_whitehead_lemma_and_k_1 (end)